TransformerModel(
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-3): 4 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (linear1): Linear(in_features=128, out_features=512, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=512, out_features=128, bias=True)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (transformer_decoder): TransformerDecoder(
    (layers): ModuleList(
      (0-3): 4 x TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (linear1): Linear(in_features=128, out_features=512, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=512, out_features=128, bias=True)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
        (dropout3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (lin): Linear(in_features=12672, out_features=20, bias=True)
  (emb): Linear(in_features=20, out_features=128, bias=True)
)
Total number of trainable parameters: 2107540
| Epoch: 0000 | lr: 10.000000E-6 | loss: 43.903162 | acc: [001528/004464] 34.229% | [004464/022297] |
| Epoch: 0000 | lr: 10.000000E-6 | loss: 43.011901 | acc: [003572/008928] 40.009% | [008928/022297] |
| Epoch: 0000 | lr: 10.000000E-6 | loss: 42.353477 | acc: [005912/013392] 44.146% | [013392/022297] |
| Epoch: 0000 | lr: 10.000000E-6 | loss: 41.924099 | acc: [008366/017856] 46.853% | [017856/022297] |
================================================================================
Avg train loss: 41.558985 Accuracy: 49.168%
================================================================================
Avg Test Error Epoch 0000 Loss: 80.107288 Accuracy: 57.751%
Best Epoch: 0! Model Saved
================================================================================
| Epoch: 0001 | lr: 9.500000E-6 | loss: 39.672895 | acc: [002754/004464] 61.694% | [004464/022297] |
| Epoch: 0001 | lr: 9.500000E-6 | loss: 39.768465 | acc: [005444/008928] 60.977% | [008928/022297] |
| Epoch: 0001 | lr: 9.500000E-6 | loss: 39.637822 | acc: [008281/013392] 61.835% | [013392/022297] |
| Epoch: 0001 | lr: 9.500000E-6 | loss: 39.563440 | acc: [011128/017856] 62.321% | [017856/022297] |
================================================================================
Avg train loss: 39.434598 Accuracy: 63.085%
================================================================================
Avg Test Error Epoch 0001 Loss: 78.061610 Accuracy: 65.333%
Best Epoch: 1! Model Saved
================================================================================
| Epoch: 0002 | lr: 9.025000E-6 | loss: 38.696896 | acc: [003038/004464] 68.056% | [004464/022297] |
| Epoch: 0002 | lr: 9.025000E-6 | loss: 38.626749 | acc: [006138/008928] 68.750% | [008928/022297] |
| Epoch: 0002 | lr: 9.025000E-6 | loss: 38.587376 | acc: [009266/013392] 69.191% | [013392/022297] |
| Epoch: 0002 | lr: 9.025000E-6 | loss: 38.549579 | acc: [012395/017856] 69.416% | [017856/022297] |
================================================================================
Avg train loss: 38.468897 Accuracy: 69.843%
================================================================================
Avg Test Error Epoch 0002 Loss: 76.731100 Accuracy: 69.104%
Best Epoch: 2! Model Saved
================================================================================
| Epoch: 0003 | lr: 8.573750E-6 | loss: 38.076624 | acc: [003223/004464] 72.200% | [004464/022297] |
| Epoch: 0003 | lr: 8.573750E-6 | loss: 38.077636 | acc: [006452/008928] 72.267% | [008928/022297] |
| Epoch: 0003 | lr: 8.573750E-6 | loss: 38.000923 | acc: [009732/013392] 72.670% | [013392/022297] |
| Epoch: 0003 | lr: 8.573750E-6 | loss: 37.936243 | acc: [013039/017856] 73.023% | [017856/022297] |
================================================================================
Avg train loss: 37.885978 Accuracy: 73.180%
================================================================================
Avg Test Error Epoch 0003 Loss: 76.037898 Accuracy: 71.158%
Best Epoch: 3! Model Saved
================================================================================
| Epoch: 0004 | lr: 8.145062E-6 | loss: 37.661723 | acc: [003324/004464] 74.462% | [004464/022297] |
| Epoch: 0004 | lr: 8.145062E-6 | loss: 37.591320 | acc: [006703/008928] 75.078% | [008928/022297] |
| Epoch: 0004 | lr: 8.145062E-6 | loss: 37.562208 | acc: [010068/013392] 75.179% | [013392/022297] |
| Epoch: 0004 | lr: 8.145062E-6 | loss: 37.572250 | acc: [013402/017856] 75.056% | [017856/022297] |
================================================================================
Avg train loss: 37.534090 Accuracy: 75.203%
Avg Test Error Epoch 0004 Loss: 75.499641 Accuracy: 72.861%
Best Epoch: 4! Model Saved
================================================================================
| Epoch: 0005 | lr: 7.737809E-6 | loss: 37.243647 | acc: [003452/004464] 77.330% | [004464/022297] |
  0%|â–‹                                                                                                                                           | 5/1000 [33:21<102:12:55, 369.83s/it] 
| Epoch: 0005 | lr: 7.737809E-6 | loss: 37.350386 | acc: [006819/008928] 76.378% | [008928/022297] |
| Epoch: 0005 | lr: 7.737809E-6 | loss: 37.306922 | acc: [010261/013392] 76.620% | [013392/022297] |
| Epoch: 0005 | lr: 7.737809E-6 | loss: 37.290172 | acc: [013685/017856] 76.641% | [017856/022297] |
================================================================================
Avg train loss: 37.267503 Accuracy: 76.678%
================================================================================
Avg Test Error Epoch 0005 Loss: 75.206869 Accuracy: 73.686%
Best Epoch: 5! Model Saved
================================================================================
| Epoch: 0006 | lr: 7.350919E-6 | loss: 37.096088 | acc: [003478/004464] 77.912% | [004464/022297] |
| Epoch: 0006 | lr: 7.350919E-6 | loss: 37.121110 | acc: [006932/008928] 77.643% | [008928/022297] |
| Epoch: 0006 | lr: 7.350919E-6 | loss: 37.087657 | acc: [010430/013392] 77.882% | [013392/022297] |
| Epoch: 0006 | lr: 7.350919E-6 | loss: 37.077262 | acc: [013902/017856] 77.856% | [017856/022297] |
================================================================================
Avg train loss: 37.058573 Accuracy: 77.854%
================================================================================
Avg Test Error Epoch 0006 Loss: 75.015873 Accuracy: 74.267%
Best Epoch: 6! Model Saved
================================================================================
| Epoch: 0007 | lr: 6.983373E-6 | loss: 36.848927 | acc: [003537/004464] 79.234% | [004464/022297] |
| Epoch: 0007 | lr: 6.983373E-6 | loss: 36.873143 | acc: [007070/008928] 79.189% | [008928/022297] |
| Epoch: 0007 | lr: 6.983373E-6 | loss: 36.927289 | acc: [010544/013392] 78.734% | [013392/022297] |
| Epoch: 0007 | lr: 6.983373E-6 | loss: 36.887280 | acc: [014102/017856] 78.976% | [017856/022297] |
================================================================================
Avg train loss: 36.887871 Accuracy: 78.899%
================================================================================
Avg Test Error Epoch 0007 Loss: 74.634581 Accuracy: 75.713%
Best Epoch: 7! Model Saved
================================================================================
| Epoch: 0008 | lr: 6.634204E-6 | loss: 36.791699 | acc: [003545/004464] 79.413% | [004464/022297] |
| Epoch: 0008 | lr: 6.634204E-6 | loss: 36.803138 | acc: [007073/008928] 79.223% | [008928/022297] |
| Epoch: 0008 | lr: 6.634204E-6 | loss: 36.785596 | acc: [010622/013392] 79.316% | [013392/022297] |
| Epoch: 0008 | lr: 6.634204E-6 | loss: 36.800710 | acc: [014154/017856] 79.267% | [017856/022297] |
================================================================================
Avg train loss: 36.759634 Accuracy: 79.419%
================================================================================
Avg Test Error Epoch 0008 Loss: 74.494454 Accuracy: 75.997%
Best Epoch: 8! Model Saved
================================================================================
| Epoch: 0009 | lr: 6.302494E-6 | loss: 36.752936 | acc: [003547/004464] 79.458% | [004464/022297] |
| Epoch: 0009 | lr: 6.302494E-6 | loss: 36.676273 | acc: [007136/008928] 79.928% | [008928/022297] |
| Epoch: 0009 | lr: 6.302494E-6 | loss: 36.666032 | acc: [010715/013392] 80.010% | [013392/022297] |
| Epoch: 0009 | lr: 6.302494E-6 | loss: 36.660603 | acc: [014295/017856] 80.057% | [017856/022297] |
================================================================================
Avg train loss: 36.666277 Accuracy: 79.975%
================================================================================
Avg Test Error Epoch 0009 Loss: 74.355253 Accuracy: 76.335%
Best Epoch: 9! Model Saved
================================================================================
| Epoch: 0010 | lr: 5.987369E-6 | loss: 36.647823 | acc: [003582/004464] 80.242% | [004464/022297] |
| Epoch: 0010 | lr: 5.987369E-6 | loss: 36.704942 | acc: [007124/008928] 79.794% | [008928/022297] |
| Epoch: 0010 | lr: 5.987369E-6 | loss: 36.643131 | acc: [010737/013392] 80.175% | [013392/022297] |
| Epoch: 0010 | lr: 5.987369E-6 | loss: 36.616456 | acc: [014340/017856] 80.309% | [017856/022297] |
================================================================================
Avg train loss: 36.590982 Accuracy: 80.361%
================================================================================
Avg Test Error Epoch 0010 Loss: 74.278375 Accuracy: 76.497%
Best Epoch: 10! Model Saved
================================================================================
| Epoch: 0011 | lr: 5.688001E-6 | loss: 36.647737 | acc: [003566/004464] 79.884% | [004464/022297] |
| Epoch: 0011 | lr: 5.688001E-6 | loss: 36.555143 | acc: [007196/008928] 80.600% | [008928/022297] |
| Epoch: 0011 | lr: 5.688001E-6 | loss: 36.524025 | acc: [010817/013392] 80.772% | [013392/022297] |
| Epoch: 0011 | lr: 5.688001E-6 | loss: 36.523521 | acc: [014412/017856] 80.712% | [017856/022297] |
================================================================================
Avg train loss: 36.529731 Accuracy: 80.589%
================================================================================
Avg Test Error Epoch 0011 Loss: 74.225552 Accuracy: 76.564%
Best Epoch: 11! Model Saved